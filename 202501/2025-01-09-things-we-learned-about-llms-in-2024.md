# Things we learned about LLMs in 2024
- URL: https://simonwillison.net/2024/Dec/31/llms-in-2024/
- Added At: 2025-01-09 08:48:10
- [Link To Text](2025-01-09-things-we-learned-about-llms-in-2024_raw.md)

## TL;DR
2024年，AI领域取得显著进展，多个模型超越GPT-4，个人电脑上运行高级模型成为可能，LLM价格大幅下降，多模态模型普及，语音和实时摄像头功能实现。然而，免费访问最佳模型的时代结束，代理功能仍未成熟，评估和批评成为关键。Apple Intelligence表现不佳，合成训练数据效果显著，但LLM使用难度增加，知识分布不均衡。

## Summary
1. **GPT-4屏障被全面突破**：
   - 2023年时，OpenAI的GPT-4是领先的模型，其他AI实验室无法超越。
   - 2024年，18个组织的70个模型在Chatbot Arena排行榜上超越了GPT-4。
   - 谷歌的Gemini 1.5 Pro是首个突破GPT-4的模型，引入了100万和200万token的上下文长度，并支持视频输入。
   - Anthropic的Claude 3系列在3月发布，Claude 3 Opus成为作者的日常使用模型，Claude 3.5 Sonnet在6月发布后成为作者的最爱。

2. **部分GPT-4级模型可在个人电脑上运行**：
   - 作者使用2023年的64GB M2 MacBook Pro运行多个GPT-4级模型。
   - Qwen2.5-Coder-32B和Meta的Llama 3.3 70B等模型可以在作者的笔记本电脑上运行。
   - 这些模型占用了大量内存，但运行效率的提升使得在个人设备上运行高级模型成为可能。

3. **LLM价格大幅下降**：
   - 2024年，顶级LLM的推理成本大幅下降。
   - OpenAI的GPT-4o价格降至2.50美元/百万token，GPT-4o mini降至0.15美元/百万token。
   - 谷歌的Gemini 1.5 Flash价格降至0.075美元/百万token，Gemini 1.5 Flash 8B降至0.0375美元/百万token。
   - 价格下降的主要原因是竞争加剧和效率提升。

4. **多模态视觉模型普及，音频和视频模型开始出现**：
   - 2024年，几乎所有主要模型供应商都发布了多模态模型。
   - 谷歌的Gemini 1.5 Pro支持图像、音频和视频输入。
   - OpenAI在10月发布了支持音频输入和输出的模型。
   - 作者升级了自己的LLM CLI工具，支持通过附件处理多模态模型。

5. **语音和实时摄像头模式成为现实**：
   - OpenAI的GPT-4o在5月发布了全新的语音模式，支持音频输入和输出。
   - 谷歌的Gemini和亚马逊的Nova也推出了类似的语音模式。
   - 12月，ChatGPT和Gemini推出了实时视频功能，用户可以通过摄像头与模型进行实时对话。

6. **基于提示的应用生成已成为商品**：
   - 2024年，基于提示生成完整应用的功能变得普遍。
   - Anthropic的Claude Artifacts允许用户直接在Claude界面中使用生成的应用。
   - GitHub、Mistral Chat等平台也推出了类似功能。
   - 作者使用Claude Artifacts生成了多个工具，并计划在Datasette项目中实现类似功能。

7. **最佳模型的免费访问仅持续了几个月**：
   - 2024年5月，OpenAI的GPT-4o和Anthropic的Claude 3.5 Sonnet免费向所有用户开放。
   - 11月，OpenAI推出了ChatGPT Pro订阅服务，用户需支付200美元/月才能访问最强大的模型o1 Pro。
   - 作者认为，免费访问最佳模型的时代可能已经结束。

8. **“代理”仍未真正实现**：
   - 作者对“代理”这一术语的模糊定义感到困惑。
   - 尽管许多人在讨论“代理”，但作者认为其实际效用仍然存疑，主要因为LLM的“轻信”问题。
   - 作者认为，解决轻信问题可能需要AGI级别的模型。

9. **评估（Evals）至关重要**：
   - 2024年，编写良好的自动化评估成为构建LLM应用的关键技能。
   - Anthropic的Amanda Askell强调了测试驱动开发的重要性。
   - 作者仍在探索如何为自己的工作实施最佳评估模式。

10. **Apple Intelligence表现不佳，MLX库表现优异**：
    - 作为Mac用户，作者对Apple的MLX库感到满意，它使得在Mac上运行模型变得更加容易。
    - 然而，Apple的“Apple Intelligence”功能表现不佳，作者认为其功能远不及前沿LLM的能力。

11. **推理扩展的“推理”模型崛起**：
    - 2024年第四季度，OpenAI推出了o1模型，引入了“推理token”的概念。
    - o1模型通过增加推理计算量来解决更复杂的问题，而不是仅仅依赖训练时的计算资源。
    - o3模型在12月发布，展示了在ARC-AGI基准测试中的优异表现。

12. **环境影响的改善与恶化**：
    - 2024年，LLM的能效提升使得单个推理的环境影响有所改善。
    - 然而，大规模AI数据中心的建设对环境的影响仍然令人担忧。

13. **合成训练数据效果显著**：
    - 2024年，合成训练数据的使用取得了显著效果，帮助提升了模型的性能。

14. **LLM使用难度增加**：
    - 尽管LLM的能力不断提升，但其使用难度也在增加，用户需要更多的技能来有效利用这些模型。

15. **知识分布极不均衡**：
    - 2024年，LLM的知识分布仍然极不均衡，某些领域的知识覆盖较好，而其他领域则相对薄弱。

16. **LLM需要更好的批评**：
    - 作者认为，LLM领域需要更多的批评和改进，以推动技术的进一步发展。

17. **2024年LLM领域的“垃圾年”**：
    - 作者将2024年称为“垃圾年”，指的是LLM领域的一些低质量内容和应用的泛滥。

18. **LLM在2024年的博客标签**：
    - 作者总结了2024年博客中所有与LLM相关的标签内容，涵盖了LLM领域的多个方面。
